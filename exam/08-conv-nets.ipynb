{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv Nets\n",
    "MatMult complexity scales with input size, i.e. becomes expensive and usies a lot of parameters for large inputs\n",
    "\n",
    "Architecture - 3 dimensions\n",
    "* Height\n",
    "* Width\n",
    "* Depth\n",
    "\n",
    "## Conv Layer\n",
    "Parameters: Learnable filters\n",
    "* Conv layer has many filters\n",
    "\n",
    "### A Filter \n",
    "3 dimensions [H, W, K]\n",
    "* H: Height\n",
    "* W: Width\n",
    "* K: Channels, ex RGB for images (K=3)\n",
    "\n",
    "Forward pass of network\n",
    "* Each filter slides (convolves) across height and width of input\n",
    "* Produces 2D activation map\n",
    "    * Learn filters that activate when they see edges, or similar features\n",
    "* Stack 2D activation for each filter $\\rightarrow$ 3D filter map output\n",
    "\n",
    "### Local connectivity and Receptive Fields\n",
    "Each neuron is connected to a small region of the input volume. The region is then called the neurons receptive field.\n",
    "\n",
    "\n",
    "#### Example 1\n",
    "Input vol [32x32x3] = [H, W, K]\n",
    "* Filter size [5x5] = [M, N]\n",
    "* Each neuron will have assigned a [M, N, K] = [5,5,3] region of the volume\n",
    "    * Number of weights: $5 \\cdot 5 \\cdot 3 = 75$ + a bias parameter (76)\n",
    "\n",
    "\n",
    "#### Example 2\n",
    "Input vol [16x16x20] = [H, W, K]\n",
    "* Filter size [3x3] = [M, N]\n",
    "* Each neuron will have assigned a [M, N, K] = [3x3x20] region of the volume\n",
    "    * Number of weights: $3 \\cdot 3 \\cdot 20 = 180$ + a bias parameter (181)\n",
    "\n",
    "### Spatial Arrangement\n",
    "How many neurons per layer - and how are they arranged?\n",
    "\n",
    "Output size is determined by three parameters:\n",
    "* Depth ~ Number of filters \n",
    "* Stride ~ How many pixels we slide each filter, no skipping means stride is 1. Higher stride values means smaller output size\n",
    "* Zero-Padding ~ Allows us to control output volume size, such that it can match input size.\n",
    "\n",
    "Let the following be all the parameters\n",
    "* $W$: Input volume size\n",
    "* $F$: Receptive field size of neurons\n",
    "* $S$: Stride\n",
    "* $P$: Amount of zero padding used\n",
    "\n",
    "Output size is then $$size = \\frac{W-F+2P}{S} + 1$$\n",
    "\n",
    "#### Example\n",
    "Input size 7x7, Filter size 3x3, S = 1, No padding\n",
    "\n",
    "$$size = \\frac{7 - 3 + 2\\cdot 0}{1} + 1 = 4 + 1 = 5 \\text{ i.e.} \\ 5\\times 5$$ \n",
    "\n",
    "Input size 7x7, Filter size 3x3, S = 2, No padding\n",
    "\n",
    "$$size = \\frac{7 - 3 + 2\\cdot 0}{1} + 1 = 2 + 1 = 3 \\text{ i.e.} \\ 3\\times 3$$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Sharing\n",
    "Idea: If one set of weights are good at identifying some feature at some region in the output, it's a good idea to assign those parameters to neurons at other regions\n",
    "\n",
    "## Pooling Layer\n",
    "Reduce the spatial size of the representation, to reduce the number of parameters used down the line in the network.\n",
    "\n",
    "Max Pooling is the most common with 2x2 and a stride of 2, this dicards 75% of activations down the line.\n",
    "\n",
    "Concretely:\n",
    "* Input ~ Volume of size $W_1 \\times H_1 \\times D_1$\n",
    "* Hyperparams\n",
    "    * Spatial extentnt $F$, often $2\\times 2$\n",
    "    * Stride $S$, often $2$\n",
    "* Output ~ Volumze of size $W_2 \\times H_2 \\times D_2$\n",
    "    * $W_2 = \\frac{W_1 - F}{S} +1$\n",
    "    * $H_2 = \\frac{H_1 - F}{S} +1$\n",
    "    * $D_2 = D_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
